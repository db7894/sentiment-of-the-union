{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'state-of-the-union-corpus-1989-2017'\n",
    "dirs = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(path, dirs[0])\n",
    "text_file = open(filename, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = lines.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "from textstat.textstat import textstatistics, easy_word_set, legacy_round "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_sentences(text): \n",
    "    nlp = spacy.load('en') \n",
    "    doc = nlp(text) \n",
    "    return doc.sents\n",
    "\n",
    "# Returns Number of Words in the text \n",
    "def word_count(text): \n",
    "    sentences = break_sentences(text) \n",
    "    words = 0\n",
    "    for sentence in sentences: \n",
    "        words += len([token for token in sentence]) \n",
    "    return words \n",
    "  \n",
    "# Returns the number of sentences in the text \n",
    "def sentence_count(text): \n",
    "    sentences = break_sentences(text) \n",
    "    return len(sentences) \n",
    "  \n",
    "# Returns average sentence length \n",
    "def avg_sentence_length(text): \n",
    "    words = word_count(text) \n",
    "    sentences = sentence_count(text) \n",
    "    average_sentence_length = float(words / sentences) \n",
    "    return average_sentence_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Textstat is a python package, to calculate statistics from  \n",
    "# text to determine readability,  \n",
    "# complexity and grade level of a particular corpus. \n",
    "# Package can be found at https://pypi.python.org/pypi/textstat \n",
    "def syllables_count(word): \n",
    "    return textstatistics().syllable_count(word) \n",
    "  \n",
    "# Returns the average number of syllables per \n",
    "# word in the text \n",
    "def avg_syllables_per_word(text): \n",
    "    syllable = syllables_count(text) \n",
    "    words = word_count(text) \n",
    "    ASPW = float(syllable) / float(words) \n",
    "    return legacy_round(ASPW, 1) \n",
    "  \n",
    "# Return total Difficult Words in a text \n",
    "def difficult_words(text): \n",
    "  \n",
    "    # Find all words in the text \n",
    "    words = [] \n",
    "    sentences = break_sentences(text) \n",
    "    for sentence in sentences: \n",
    "        words += [str(token) for token in sentence] \n",
    "  \n",
    "    # difficult words are those with syllables >= 2 \n",
    "    # easy_word_set is provide by Textstat as  \n",
    "    # a list of common words \n",
    "    diff_words_set = set() \n",
    "      \n",
    "    for word in words: \n",
    "        syllable_count = syllables_count(word) \n",
    "        if word not in easy_word_set and syllable_count >= 2: \n",
    "            diff_words_set.add(word) \n",
    "  \n",
    "    return len(diff_words_set) \n",
    "  \n",
    "# A word is polysyllablic if it has more than 3 syllables \n",
    "# this functions returns the number of all such words  \n",
    "# present in the text \n",
    "def poly_syllable_count(text): \n",
    "    count = 0\n",
    "    words = [] \n",
    "    sentences = break_sentences(text) \n",
    "    for sentence in sentences: \n",
    "        words += [token for token in sentence] \n",
    "      \n",
    "  \n",
    "    for word in words: \n",
    "        syllable_count = syllables_count(word) \n",
    "        if syllable_count >= 3: \n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flesch_reading_ease(text): \n",
    "    \"\"\" \n",
    "        Implements Flesch Formula: \n",
    "        Reading Ease score = 206.835 - (1.015 × ASL) - (84.6 × ASW) \n",
    "        Here, \n",
    "          ASL = average sentence length (number of words  \n",
    "                divided by number of sentences) \n",
    "          ASW = average word length in syllables (number of syllables  \n",
    "                divided by number of words) \n",
    "    \"\"\"\n",
    "    FRE = 206.835 - float(1.015 * avg_sentence_length(text)) - float(84.6 * avg_syllables_per_word(text)) \n",
    "    return legacy_round(FRE, 2) \n",
    "\n",
    "def gunning_fog(text): \n",
    "    per_diff_words = (difficult_words(text) / word_count(text) * 100) + 5\n",
    "    grade = 0.4 * (avg_sentence_length(text) + per_diff_words) \n",
    "    return grade \n",
    "\n",
    "def smog_index(text): \n",
    "    \"\"\" \n",
    "        Implements SMOG Formula / Grading \n",
    "        SMOG grading = 3 + ?polysyllable count. \n",
    "        Here,  \n",
    "           polysyllable count = number of words of more \n",
    "          than two syllables in a sample of 30 sentences. \n",
    "    \"\"\"\n",
    "  \n",
    "    if sentence_count(text) >= 3: \n",
    "        poly_syllab = poly_syllable_count(text) \n",
    "        SMOG = (1.043 * (30*(poly_syllab / sentence_count(text)))**0.5) + 3.1291\n",
    "        return legacy_round(SMOG, 1) \n",
    "    else: \n",
    "        return 0\n",
    "  \n",
    "  \n",
    "def dale_chall_readability_score(text): \n",
    "    \"\"\" \n",
    "        Implements Dale Challe Formula: \n",
    "        Raw score = 0.1579*(PDW) + 0.0496*(ASL) + 3.6365 \n",
    "        Here, \n",
    "            PDW = Percentage of difficult words. \n",
    "            ASL = Average sentence length \n",
    "    \"\"\"\n",
    "    words = word_count(text) \n",
    "    # Number of words not termed as difficult words \n",
    "    count = word_count - difficult_words(text) \n",
    "    if words > 0: \n",
    "  \n",
    "        # Percentage of words not on difficult word list \n",
    "  \n",
    "        per = float(count) / float(words) * 100\n",
    "      \n",
    "    # diff_words stores percentage of difficult words \n",
    "    diff_words = 100 - per \n",
    "  \n",
    "    raw_score = (0.1579 * diff_words) + (0.0496 * avg_sentence_length(text)) \n",
    "      \n",
    "    # If Percentage of Difficult Words is greater than 5 %, then; \n",
    "    # Adjusted Score = Raw Score + 3.6365, \n",
    "    # otherwise Adjusted Score = Raw Score \n",
    "  \n",
    "    if diff_words > 5:        \n",
    "  \n",
    "        raw_score += 3.6365\n",
    "          \n",
    "    return legacy_round(score, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flesch_reading_ease(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c56f2c908bbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'exists'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
